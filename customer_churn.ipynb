{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Customer Churn Prediction with XGBoost\n",
    "_**Using Gradient Boosted Trees to Predict Mobile Customer Departure**_\n",
    "\n",
    "---\n",
    "\n",
    "---\n",
    "\n",
    "## Contents\n",
    "\n",
    "1. [Background](#Background)\n",
    "1. [Setup](#Setup)\n",
    "1. [Data](#Data)\n",
    "1. [Train](#Train)\n",
    "1. [Inference Pipeline](#Inference)\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "## Background\n",
    "\n",
    "_This notebook has been adapted from an [AWS blog post](https://aws.amazon.com/blogs/ai/predicting-customer-churn-with-amazon-machine-learning/)_\n",
    "\n",
    "Losing customers is costly for any business.  Identifying unhappy customers early on gives you a chance to offer them incentives to stay.  This notebook describes using machine learning (ML) for the automated identification of unhappy customers, also known as customer churn prediction. ML models rarely give perfect predictions though, so this notebook is also about how to incorporate the relative costs of prediction mistakes when determining the financial outcome of using ML.\n",
    "\n",
    "We use an example of churn that is familiar to all of us–leaving a mobile phone operator.  Seems like I can always find fault with my provider du jour! And if my provider knows that I’m thinking of leaving, it can offer timely incentives–I can always use a phone upgrade or perhaps have a new feature activated–and I might just stick around. Incentives are often much more cost effective than losing and reacquiring a customer.\n",
    "\n",
    "---\n",
    "\n",
    "## Setup\n",
    "\n",
    "_This notebook was created and tested on an ml.m4.xlarge notebook instance._\n",
    "\n",
    "Let's start by specifying:\n",
    "\n",
    "- The S3 bucket and prefix that you want to use for training and model data. You need to create an S3 bucket to store your datasets and the model you build. Follow this [instruction](https://docs.aws.amazon.com/AmazonS3/latest/user-guide/create-bucket.html) to create an S3 bucket. This should be within the same region as the Notebook Instance, training, and hosting.\n",
    "- The IAM role arn used to give training and hosting access to your data. See the documentation for how to create these.  Note, if more than one role is required for notebook instances, training, and/or hosting, please replace the boto regexp with a the appropriate full IAM role arn string(s)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "isConfigCell": true,
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "bucket = 'quicksight-sagemaker-demo-accenture'\n",
    "prefix = 'sagemaker/QS-xgboost-churn'\n",
    "\n",
    "# Define IAM role\n",
    "import boto3\n",
    "import re\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "role = get_execution_role()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll import the Python libraries we'll need for the remainder of the exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import io\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import json\n",
    "from IPython.display import display\n",
    "from time import strftime, gmtime\n",
    "import sagemaker\n",
    "from sagemaker.predictor import csv_serializer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Data\n",
    "\n",
    "Mobile operators have historical records on which customers ultimately ended up churning and which continued using the service. We can use this historical information to construct an ML model of one mobile operator’s churn using a process called training. After training the model, we can pass the profile information of an arbitrary customer (the same profile information that we used to train the model) to the model, and have the model predict whether this customer is going to churn. Of course, we expect the model to make mistakes–after all, predicting the future is tricky business! But I’ll also show how to deal with prediction errors.\n",
    "\n",
    "The dataset we use is publicly available and was mentioned in the book [Discovering Knowledge in Data](https://www.amazon.com/dp/0470908742/) by Daniel T. Larose. It is attributed by the author to the University of California Irvine Repository of Machine Learning Datasets.  Let's download and read that dataset in now:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download: s3://sagemaker-sample-files/datasets/tabular/synthetic/churn.txt to ./churn.txt\r\n"
     ]
    }
   ],
   "source": [
    "!aws s3 cp s3://sagemaker-sample-files/datasets/tabular/synthetic/churn.txt ./"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State</th>\n",
       "      <th>Account Length</th>\n",
       "      <th>Area Code</th>\n",
       "      <th>Phone</th>\n",
       "      <th>Int'l Plan</th>\n",
       "      <th>VMail Plan</th>\n",
       "      <th>VMail Message</th>\n",
       "      <th>Day Mins</th>\n",
       "      <th>Day Calls</th>\n",
       "      <th>Day Charge</th>\n",
       "      <th>Eve Mins</th>\n",
       "      <th>Eve Calls</th>\n",
       "      <th>Eve Charge</th>\n",
       "      <th>Night Mins</th>\n",
       "      <th>Night Calls</th>\n",
       "      <th>Night Charge</th>\n",
       "      <th>Intl Mins</th>\n",
       "      <th>Intl Calls</th>\n",
       "      <th>Intl Charge</th>\n",
       "      <th>CustServ Calls</th>\n",
       "      <th>Churn?</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PA</td>\n",
       "      <td>163</td>\n",
       "      <td>806</td>\n",
       "      <td>403-2562</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>300</td>\n",
       "      <td>8.162204</td>\n",
       "      <td>3</td>\n",
       "      <td>7.579174</td>\n",
       "      <td>3.933035</td>\n",
       "      <td>4</td>\n",
       "      <td>6.508639</td>\n",
       "      <td>4.065759</td>\n",
       "      <td>100</td>\n",
       "      <td>5.111624</td>\n",
       "      <td>4.928160</td>\n",
       "      <td>6</td>\n",
       "      <td>5.673203</td>\n",
       "      <td>3</td>\n",
       "      <td>True.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SC</td>\n",
       "      <td>15</td>\n",
       "      <td>836</td>\n",
       "      <td>158-8416</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>10.018993</td>\n",
       "      <td>4</td>\n",
       "      <td>4.226289</td>\n",
       "      <td>2.325005</td>\n",
       "      <td>0</td>\n",
       "      <td>9.972592</td>\n",
       "      <td>7.141040</td>\n",
       "      <td>200</td>\n",
       "      <td>6.436188</td>\n",
       "      <td>3.221748</td>\n",
       "      <td>6</td>\n",
       "      <td>2.559749</td>\n",
       "      <td>8</td>\n",
       "      <td>False.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MO</td>\n",
       "      <td>131</td>\n",
       "      <td>777</td>\n",
       "      <td>896-6253</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>300</td>\n",
       "      <td>4.708490</td>\n",
       "      <td>3</td>\n",
       "      <td>4.768160</td>\n",
       "      <td>4.537466</td>\n",
       "      <td>3</td>\n",
       "      <td>4.566715</td>\n",
       "      <td>5.363235</td>\n",
       "      <td>100</td>\n",
       "      <td>5.142451</td>\n",
       "      <td>7.139023</td>\n",
       "      <td>2</td>\n",
       "      <td>6.254157</td>\n",
       "      <td>4</td>\n",
       "      <td>False.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>WY</td>\n",
       "      <td>75</td>\n",
       "      <td>878</td>\n",
       "      <td>817-5729</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>700</td>\n",
       "      <td>1.268734</td>\n",
       "      <td>3</td>\n",
       "      <td>2.567642</td>\n",
       "      <td>2.528748</td>\n",
       "      <td>5</td>\n",
       "      <td>2.333624</td>\n",
       "      <td>3.773586</td>\n",
       "      <td>450</td>\n",
       "      <td>3.814413</td>\n",
       "      <td>2.245779</td>\n",
       "      <td>6</td>\n",
       "      <td>1.080692</td>\n",
       "      <td>6</td>\n",
       "      <td>False.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>WY</td>\n",
       "      <td>146</td>\n",
       "      <td>878</td>\n",
       "      <td>450-4942</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>2.696177</td>\n",
       "      <td>3</td>\n",
       "      <td>5.908916</td>\n",
       "      <td>6.015337</td>\n",
       "      <td>3</td>\n",
       "      <td>3.670408</td>\n",
       "      <td>3.751673</td>\n",
       "      <td>250</td>\n",
       "      <td>2.796812</td>\n",
       "      <td>6.905545</td>\n",
       "      <td>4</td>\n",
       "      <td>7.134343</td>\n",
       "      <td>6</td>\n",
       "      <td>True.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  State  Account Length  Area Code     Phone Int'l Plan VMail Plan  \\\n",
       "0    PA             163        806  403-2562         no        yes   \n",
       "1    SC              15        836  158-8416        yes         no   \n",
       "2    MO             131        777  896-6253         no        yes   \n",
       "3    WY              75        878  817-5729        yes        yes   \n",
       "4    WY             146        878  450-4942        yes         no   \n",
       "\n",
       "   VMail Message   Day Mins  Day Calls  Day Charge  Eve Mins  Eve Calls  \\\n",
       "0            300   8.162204          3    7.579174  3.933035          4   \n",
       "1              0  10.018993          4    4.226289  2.325005          0   \n",
       "2            300   4.708490          3    4.768160  4.537466          3   \n",
       "3            700   1.268734          3    2.567642  2.528748          5   \n",
       "4              0   2.696177          3    5.908916  6.015337          3   \n",
       "\n",
       "   Eve Charge  Night Mins  Night Calls  Night Charge  Intl Mins  Intl Calls  \\\n",
       "0    6.508639    4.065759          100      5.111624   4.928160           6   \n",
       "1    9.972592    7.141040          200      6.436188   3.221748           6   \n",
       "2    4.566715    5.363235          100      5.142451   7.139023           2   \n",
       "3    2.333624    3.773586          450      3.814413   2.245779           6   \n",
       "4    3.670408    3.751673          250      2.796812   6.905545           4   \n",
       "\n",
       "   Intl Charge  CustServ Calls  Churn?  \n",
       "0     5.673203               3   True.  \n",
       "1     2.559749               8  False.  \n",
       "2     6.254157               4  False.  \n",
       "3     1.080692               6  False.  \n",
       "4     7.134343               6   True.  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "churn = pd.read_csv(\"./churn.txt\")\n",
    "pd.set_option(\"display.max_columns\", 500)\n",
    "churn.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By modern standards, it’s a relatively small dataset, with only 3,333 records, where each record uses 21 attributes to describe the profile of a customer of an unknown US mobile operator. The attributes are:\n",
    "\n",
    "- `State`: the US state in which the customer resides, indicated by a two-letter abbreviation; for example, OH or NJ\n",
    "- `Account Length`: the number of days that this account has been active\n",
    "- `Area Code`: the three-digit area code of the corresponding customer’s phone number\n",
    "- `Phone`: the remaining seven-digit phone number\n",
    "- `Int’l Plan`: whether the customer has an international calling plan: yes/no\n",
    "- `VMail Plan`: whether the customer has a voice mail feature: yes/no\n",
    "- `VMail Message`: presumably the average number of voice mail messages per month\n",
    "- `Day Mins`: the total number of calling minutes used during the day\n",
    "- `Day Calls`: the total number of calls placed during the day\n",
    "- `Day Charge`: the billed cost of daytime calls\n",
    "- `Eve Mins, Eve Calls, Eve Charge`: the billed cost for calls placed during the evening\n",
    "- `Night Mins`, `Night Calls`, `Night Charge`: the billed cost for calls placed during nighttime\n",
    "- `Intl Mins`, `Intl Calls`, `Intl Charge`: the billed cost for international calls\n",
    "- `CustServ Calls`: the number of calls placed to Customer Service\n",
    "- `Churn?`: whether the customer left the service: true/false\n",
    "\n",
    "The last attribute, `Churn?`, is known as the target attribute–the attribute that we want the ML model to predict.  Because the target attribute is binary, our model will be performing binary prediction, also known as binary classification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "let's split the data into training, validation, and test sets.  This will help prevent us from overfitting the model, and allow us to test the models accuracy on data it hasn't already seen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, validation_data, test_data = np.split(churn.sample(frac=1, random_state=1729), [int(0.7 * len(churn)), int(0.9 * len(churn))])\n",
    "train_data.to_csv('train.csv', header=False, index=False)\n",
    "validation_data.to_csv('validation.csv', header=False, index=False)\n",
    "test_data.drop('Churn?', axis=1).to_csv('test.csv', header=True, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll upload these files to S3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "boto3.Session().resource('s3').Bucket(bucket).Object(os.path.join(prefix, 'rawtrain/train.csv')).upload_file('train.csv')\n",
    "boto3.Session().resource('s3').Bucket(bucket).Object(os.path.join(prefix, 'rawvalidation/validation.csv')).upload_file('validation.csv')\n",
    "boto3.Session().resource('s3').Bucket(bucket).Object(os.path.join(prefix, 'rawtest/test.csv')).upload_file('test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, because we're training with the CSV file format, we'll create `s3_input`s that our training function can use as a pointer to the files in S3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_input_train = sagemaker.TrainingInput(s3_data='s3://{}/{}/rawtrain/'.format(bucket, prefix), content_type='csv')\n",
    "s3_input_validation = sagemaker.TrainingInput(s3_data='s3://{}/{}/rawvalidation/'.format(bucket, prefix), content_type='csv')\n",
    "s3_input_test = sagemaker.TrainingInput(s3_data='s3://{}/{}/rawtest/'.format(bucket, prefix), content_type='csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing data <a class=\"anchor\" id=\"Pre-processing\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to do typical preprocessing tasks, including cleaning, feature transformation, feature selection on input data before train the prediction model. For example:  \n",
    "- `Phone` takes on too many unique values to be of any practical use. It's possible parsing out the prefix could have some value, but without more context on how these are allocated, we should avoid using it.\n",
    "- `Area Code` showing up as a feature we should convert to non-numeric.\n",
    "- If we dig into features and run correlaiton analysis, we see several features that essentially have high correlation with one another. Including these feature pairs in some machine learning algorithms can create catastrophic problems, while in others it will only introduce minor redundancy and bias. We should remove one feature from each of the highly correlated pairs.\n",
    "\n",
    "We will use Amazon SageMaker built-in Scikit-learn library for preprocessing (and also postprocessing), and then use the Amazon SageMaker built-in XGboost algorithm for predictions. We’ll deploy both the library and the algorithm on the same endpoint using the Amazon SageMaker Inference Pipelines feature so you can pass raw input data directly to Amazon SageMaker. We’ll also reuse the preprocessing code between training and inference to reduce development overhead and errors.\n",
    "\n",
    "To run Scikit-learn on Sagemaker `SKLearn` Estimator with a script as an entry point. The training script is very similar to a training script you might run outside of SageMaker. Also, as this data set is pretty small in term of size, we use the 'local' mode for preprocessing and upload the transformer and transformed data into S3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating 0sjua2e2nm-algo-1-jjgbd ... \n",
      "Creating 0sjua2e2nm-algo-1-jjgbd ... done\n",
      "Attaching to 0sjua2e2nm-algo-1-jjgbd\n",
      "\u001b[36m0sjua2e2nm-algo-1-jjgbd |\u001b[0m 2022-01-14 21:04:29,423 sagemaker-containers INFO     Imported framework sagemaker_sklearn_container.training\n",
      "\u001b[36m0sjua2e2nm-algo-1-jjgbd |\u001b[0m 2022-01-14 21:04:29,426 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36m0sjua2e2nm-algo-1-jjgbd |\u001b[0m 2022-01-14 21:04:29,435 sagemaker_sklearn_container.training INFO     Invoking user training script.\n",
      "\u001b[36m0sjua2e2nm-algo-1-jjgbd |\u001b[0m 2022-01-14 21:04:29,897 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36m0sjua2e2nm-algo-1-jjgbd |\u001b[0m 2022-01-14 21:04:29,911 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36m0sjua2e2nm-algo-1-jjgbd |\u001b[0m 2022-01-14 21:04:29,923 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36m0sjua2e2nm-algo-1-jjgbd |\u001b[0m 2022-01-14 21:04:29,934 sagemaker-training-toolkit INFO     Invoking user script\n",
      "\u001b[36m0sjua2e2nm-algo-1-jjgbd |\u001b[0m \n",
      "\u001b[36m0sjua2e2nm-algo-1-jjgbd |\u001b[0m Training Env:\n",
      "\u001b[36m0sjua2e2nm-algo-1-jjgbd |\u001b[0m \n",
      "\u001b[36m0sjua2e2nm-algo-1-jjgbd |\u001b[0m {\n",
      "\u001b[36m0sjua2e2nm-algo-1-jjgbd |\u001b[0m     \"additional_framework_parameters\": {},\n",
      "\u001b[36m0sjua2e2nm-algo-1-jjgbd |\u001b[0m     \"channel_input_dirs\": {\n",
      "\u001b[36m0sjua2e2nm-algo-1-jjgbd |\u001b[0m         \"train\": \"/opt/ml/input/data/train\"\n",
      "\u001b[36m0sjua2e2nm-algo-1-jjgbd |\u001b[0m     },\n",
      "\u001b[36m0sjua2e2nm-algo-1-jjgbd |\u001b[0m     \"current_host\": \"algo-1-jjgbd\",\n",
      "\u001b[36m0sjua2e2nm-algo-1-jjgbd |\u001b[0m     \"framework_module\": \"sagemaker_sklearn_container.training:main\",\n",
      "\u001b[36m0sjua2e2nm-algo-1-jjgbd |\u001b[0m     \"hosts\": [\n",
      "\u001b[36m0sjua2e2nm-algo-1-jjgbd |\u001b[0m         \"algo-1-jjgbd\"\n",
      "\u001b[36m0sjua2e2nm-algo-1-jjgbd |\u001b[0m     ],\n",
      "\u001b[36m0sjua2e2nm-algo-1-jjgbd |\u001b[0m     \"hyperparameters\": {},\n",
      "\u001b[36m0sjua2e2nm-algo-1-jjgbd |\u001b[0m     \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "\u001b[36m0sjua2e2nm-algo-1-jjgbd |\u001b[0m     \"input_data_config\": {\n",
      "\u001b[36m0sjua2e2nm-algo-1-jjgbd |\u001b[0m         \"train\": {\n",
      "\u001b[36m0sjua2e2nm-algo-1-jjgbd |\u001b[0m             \"TrainingInputMode\": \"File\",\n",
      "\u001b[36m0sjua2e2nm-algo-1-jjgbd |\u001b[0m             \"ContentType\": \"csv\"\n",
      "\u001b[36m0sjua2e2nm-algo-1-jjgbd |\u001b[0m         }\n",
      "\u001b[36m0sjua2e2nm-algo-1-jjgbd |\u001b[0m     },\n",
      "\u001b[36m0sjua2e2nm-algo-1-jjgbd |\u001b[0m     \"input_dir\": \"/opt/ml/input\",\n",
      "\u001b[36m0sjua2e2nm-algo-1-jjgbd |\u001b[0m     \"is_master\": true,\n",
      "\u001b[36m0sjua2e2nm-algo-1-jjgbd |\u001b[0m     \"job_name\": \"sagemaker-scikit-learn-2022-01-14-21-03-09-151\",\n",
      "\u001b[36m0sjua2e2nm-algo-1-jjgbd |\u001b[0m     \"log_level\": 20,\n",
      "\u001b[36m0sjua2e2nm-algo-1-jjgbd |\u001b[0m     \"master_hostname\": \"algo-1-jjgbd\",\n",
      "\u001b[36m0sjua2e2nm-algo-1-jjgbd |\u001b[0m     \"model_dir\": \"/opt/ml/model\",\n",
      "\u001b[36m0sjua2e2nm-algo-1-jjgbd |\u001b[0m     \"module_dir\": \"s3://sagemaker-us-east-1-048119352545/sagemaker-scikit-learn-2022-01-14-21-03-09-151/source/sourcedir.tar.gz\",\n",
      "\u001b[36m0sjua2e2nm-algo-1-jjgbd |\u001b[0m     \"module_name\": \"preprocessing\",\n",
      "\u001b[36m0sjua2e2nm-algo-1-jjgbd |\u001b[0m     \"network_interface_name\": \"eth0\",\n",
      "\u001b[36m0sjua2e2nm-algo-1-jjgbd |\u001b[0m     \"num_cpus\": 2,\n",
      "\u001b[36m0sjua2e2nm-algo-1-jjgbd |\u001b[0m     \"num_gpus\": 0,\n",
      "\u001b[36m0sjua2e2nm-algo-1-jjgbd |\u001b[0m     \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "\u001b[36m0sjua2e2nm-algo-1-jjgbd |\u001b[0m     \"output_dir\": \"/opt/ml/output\",\n",
      "\u001b[36m0sjua2e2nm-algo-1-jjgbd |\u001b[0m     \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "\u001b[36m0sjua2e2nm-algo-1-jjgbd |\u001b[0m     \"resource_config\": {\n",
      "\u001b[36m0sjua2e2nm-algo-1-jjgbd |\u001b[0m         \"current_host\": \"algo-1-jjgbd\",\n",
      "\u001b[36m0sjua2e2nm-algo-1-jjgbd |\u001b[0m         \"hosts\": [\n",
      "\u001b[36m0sjua2e2nm-algo-1-jjgbd |\u001b[0m             \"algo-1-jjgbd\"\n",
      "\u001b[36m0sjua2e2nm-algo-1-jjgbd |\u001b[0m         ]\n",
      "\u001b[36m0sjua2e2nm-algo-1-jjgbd |\u001b[0m     },\n",
      "\u001b[36m0sjua2e2nm-algo-1-jjgbd |\u001b[0m     \"user_entry_point\": \"preprocessing.py\"\n",
      "\u001b[36m0sjua2e2nm-algo-1-jjgbd |\u001b[0m }\n",
      "\u001b[36m0sjua2e2nm-algo-1-jjgbd |\u001b[0m \n",
      "\u001b[36m0sjua2e2nm-algo-1-jjgbd |\u001b[0m Environment variables:\n",
      "\u001b[36m0sjua2e2nm-algo-1-jjgbd |\u001b[0m \n",
      "\u001b[36m0sjua2e2nm-algo-1-jjgbd |\u001b[0m SM_HOSTS=[\"algo-1-jjgbd\"]\n",
      "\u001b[36m0sjua2e2nm-algo-1-jjgbd |\u001b[0m SM_NETWORK_INTERFACE_NAME=eth0\n",
      "\u001b[36m0sjua2e2nm-algo-1-jjgbd |\u001b[0m SM_HPS={}\n",
      "\u001b[36m0sjua2e2nm-algo-1-jjgbd |\u001b[0m SM_USER_ENTRY_POINT=preprocessing.py\n",
      "\u001b[36m0sjua2e2nm-algo-1-jjgbd |\u001b[0m SM_FRAMEWORK_PARAMS={}\n",
      "\u001b[36m0sjua2e2nm-algo-1-jjgbd |\u001b[0m SM_RESOURCE_CONFIG={\"current_host\":\"algo-1-jjgbd\",\"hosts\":[\"algo-1-jjgbd\"]}\n",
      "\u001b[36m0sjua2e2nm-algo-1-jjgbd |\u001b[0m SM_INPUT_DATA_CONFIG={\"train\":{\"ContentType\":\"csv\",\"TrainingInputMode\":\"File\"}}\n",
      "\u001b[36m0sjua2e2nm-algo-1-jjgbd |\u001b[0m SM_OUTPUT_DATA_DIR=/opt/ml/output/data\n",
      "\u001b[36m0sjua2e2nm-algo-1-jjgbd |\u001b[0m SM_CHANNELS=[\"train\"]\n",
      "\u001b[36m0sjua2e2nm-algo-1-jjgbd |\u001b[0m SM_CURRENT_HOST=algo-1-jjgbd\n",
      "\u001b[36m0sjua2e2nm-algo-1-jjgbd |\u001b[0m SM_MODULE_NAME=preprocessing\n",
      "\u001b[36m0sjua2e2nm-algo-1-jjgbd |\u001b[0m SM_LOG_LEVEL=20\n",
      "\u001b[36m0sjua2e2nm-algo-1-jjgbd |\u001b[0m SM_FRAMEWORK_MODULE=sagemaker_sklearn_container.training:main\n",
      "\u001b[36m0sjua2e2nm-algo-1-jjgbd |\u001b[0m SM_INPUT_DIR=/opt/ml/input\n",
      "\u001b[36m0sjua2e2nm-algo-1-jjgbd |\u001b[0m SM_INPUT_CONFIG_DIR=/opt/ml/input/config\n",
      "\u001b[36m0sjua2e2nm-algo-1-jjgbd |\u001b[0m SM_OUTPUT_DIR=/opt/ml/output\n",
      "\u001b[36m0sjua2e2nm-algo-1-jjgbd |\u001b[0m SM_NUM_CPUS=2\n",
      "\u001b[36m0sjua2e2nm-algo-1-jjgbd |\u001b[0m SM_NUM_GPUS=0\n",
      "\u001b[36m0sjua2e2nm-algo-1-jjgbd |\u001b[0m SM_MODEL_DIR=/opt/ml/model\n",
      "\u001b[36m0sjua2e2nm-algo-1-jjgbd |\u001b[0m SM_MODULE_DIR=s3://sagemaker-us-east-1-048119352545/sagemaker-scikit-learn-2022-01-14-21-03-09-151/source/sourcedir.tar.gz\n",
      "\u001b[36m0sjua2e2nm-algo-1-jjgbd |\u001b[0m SM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"train\":\"/opt/ml/input/data/train\"},\"current_host\":\"algo-1-jjgbd\",\"framework_module\":\"sagemaker_sklearn_container.training:main\",\"hosts\":[\"algo-1-jjgbd\"],\"hyperparameters\":{},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"train\":{\"ContentType\":\"csv\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"sagemaker-scikit-learn-2022-01-14-21-03-09-151\",\"log_level\":20,\"master_hostname\":\"algo-1-jjgbd\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-1-048119352545/sagemaker-scikit-learn-2022-01-14-21-03-09-151/source/sourcedir.tar.gz\",\"module_name\":\"preprocessing\",\"network_interface_name\":\"eth0\",\"num_cpus\":2,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1-jjgbd\",\"hosts\":[\"algo-1-jjgbd\"]},\"user_entry_point\":\"preprocessing.py\"}\n",
      "\u001b[36m0sjua2e2nm-algo-1-jjgbd |\u001b[0m SM_USER_ARGS=[]\n",
      "\u001b[36m0sjua2e2nm-algo-1-jjgbd |\u001b[0m SM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\n",
      "\u001b[36m0sjua2e2nm-algo-1-jjgbd |\u001b[0m SM_CHANNEL_TRAIN=/opt/ml/input/data/train\n",
      "\u001b[36m0sjua2e2nm-algo-1-jjgbd |\u001b[0m PYTHONPATH=/opt/ml/code:/miniconda3/bin:/miniconda3/lib/python37.zip:/miniconda3/lib/python3.7:/miniconda3/lib/python3.7/lib-dynload:/miniconda3/lib/python3.7/site-packages\n",
      "\u001b[36m0sjua2e2nm-algo-1-jjgbd |\u001b[0m \n",
      "\u001b[36m0sjua2e2nm-algo-1-jjgbd |\u001b[0m Invoking script with the following command:\n",
      "\u001b[36m0sjua2e2nm-algo-1-jjgbd |\u001b[0m \n",
      "\u001b[36m0sjua2e2nm-algo-1-jjgbd |\u001b[0m /miniconda3/bin/python preprocessing.py\n",
      "\u001b[36m0sjua2e2nm-algo-1-jjgbd |\u001b[0m \n",
      "\u001b[36m0sjua2e2nm-algo-1-jjgbd |\u001b[0m \n",
      "\u001b[36m0sjua2e2nm-algo-1-jjgbd |\u001b[0m /miniconda3/lib/python3.7/site-packages/sklearn/externals/joblib/externals/cloudpickle/cloudpickle.py:47: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n",
      "\u001b[36m0sjua2e2nm-algo-1-jjgbd |\u001b[0m   import imp\n",
      "\u001b[36m0sjua2e2nm-algo-1-jjgbd |\u001b[0m /miniconda3/lib/python3.7/site-packages/sklearn/externals/joblib/numpy_pickle.py:104: DeprecationWarning: tostring() is deprecated. Use tobytes() instead.\n",
      "\u001b[36m0sjua2e2nm-algo-1-jjgbd |\u001b[0m   pickler.file_handle.write(chunk.tostring('C'))\n",
      "\u001b[36m0sjua2e2nm-algo-1-jjgbd |\u001b[0m /miniconda3/lib/python3.7/site-packages/sklearn/externals/joblib/numpy_pickle.py:104: DeprecationWarning: tostring() is deprecated. Use tobytes() instead.\n",
      "\u001b[36m0sjua2e2nm-algo-1-jjgbd |\u001b[0m   pickler.file_handle.write(chunk.tostring('C'))\n",
      "\u001b[36m0sjua2e2nm-algo-1-jjgbd |\u001b[0m /miniconda3/lib/python3.7/site-packages/sklearn/externals/joblib/numpy_pickle.py:104: DeprecationWarning: tostring() is deprecated. Use tobytes() instead.\n",
      "\u001b[36m0sjua2e2nm-algo-1-jjgbd |\u001b[0m   pickler.file_handle.write(chunk.tostring('C'))\n",
      "\u001b[36m0sjua2e2nm-algo-1-jjgbd |\u001b[0m /miniconda3/lib/python3.7/site-packages/sklearn/externals/joblib/numpy_pickle.py:104: DeprecationWarning: tostring() is deprecated. Use tobytes() instead.\n",
      "\u001b[36m0sjua2e2nm-algo-1-jjgbd |\u001b[0m   pickler.file_handle.write(chunk.tostring('C'))\n",
      "\u001b[36m0sjua2e2nm-algo-1-jjgbd |\u001b[0m saved model!\n",
      "\u001b[36m0sjua2e2nm-algo-1-jjgbd |\u001b[0m 2022-01-14 21:04:31,172 sagemaker-containers INFO     Reporting training SUCCESS\n",
      "\u001b[36m0sjua2e2nm-algo-1-jjgbd exited with code 0\n",
      "\u001b[0mAborting on container exit...\n",
      "===== Job Complete =====\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.sklearn.estimator import SKLearn\n",
    "sagemaker_session = sagemaker.Session()\n",
    "git_config = {'repo': 'https://github.com/aws-samples/quicksight-sagemaker-integration-blog.git','branch': 'master'}\n",
    "\n",
    "script_path = 'quicksight-sagemaker-integration/preprocessing.py'\n",
    "\n",
    "sklearn_preprocessor = SKLearn(\n",
    "    entry_point=script_path,\n",
    "    git_config=git_config,\n",
    "    role=role,\n",
    "    instance_type=\"local\",\n",
    "    framework_version=\"0.20.0\")\n",
    "sklearn_preprocessor.fit({'train': s3_input_train})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing the training and validation dataset <a class=\"anchor\" id=\"preprocess_train_data\"></a>\n",
    "Now that our proprocessor is properly fitted, let's go ahead and preprocess our training and validation data. Let's use batch transform to directly preprocess the raw data and store right back into s3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attaching to eode3rs7bp-algo-1-wkmri\n",
      "\u001b[36meode3rs7bp-algo-1-wkmri |\u001b[0m Processing /opt/ml/code\n",
      "\u001b[36meode3rs7bp-algo-1-wkmri |\u001b[0m Building wheels for collected packages: preprocessing\n",
      "\u001b[36meode3rs7bp-algo-1-wkmri |\u001b[0m   Building wheel for preprocessing (setup.py) ... \u001b[?25ldone\n",
      "\u001b[36meode3rs7bp-algo-1-wkmri |\u001b[0m \u001b[?25h  Created wheel for preprocessing: filename=preprocessing-1.0.0-py2.py3-none-any.whl size=8211 sha256=e78ee72d7827862791134a280694033a7baaca8f836c4e86d83b43a7d2a51ab3\n",
      "\u001b[36meode3rs7bp-algo-1-wkmri |\u001b[0m   Stored in directory: /tmp/pip-ephem-wheel-cache-g7whnfwm/wheels/3e/0f/51/2f1df833dd0412c1bc2f5ee56baac195b5be563353d111dca6\n",
      "\u001b[36meode3rs7bp-algo-1-wkmri |\u001b[0m Successfully built preprocessing\n",
      "\u001b[36meode3rs7bp-algo-1-wkmri |\u001b[0m Installing collected packages: preprocessing\n",
      "\u001b[36meode3rs7bp-algo-1-wkmri |\u001b[0m Successfully installed preprocessing-1.0.0\n",
      "\u001b[36meode3rs7bp-algo-1-wkmri |\u001b[0m /miniconda3/lib/python3.7/site-packages/sklearn/externals/joblib/externals/cloudpickle/cloudpickle.py:47: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n",
      "\u001b[36meode3rs7bp-algo-1-wkmri |\u001b[0m   import imp\n",
      "\u001b[36meode3rs7bp-algo-1-wkmri |\u001b[0m [2022-01-14 21:04:36 +0000] [31] [INFO] Starting gunicorn 20.1.0\n",
      "\u001b[36meode3rs7bp-algo-1-wkmri |\u001b[0m [2022-01-14 21:04:36 +0000] [31] [INFO] Listening at: unix:/tmp/gunicorn.sock (31)\n",
      "\u001b[36meode3rs7bp-algo-1-wkmri |\u001b[0m [2022-01-14 21:04:36 +0000] [31] [INFO] Using worker: gevent\n",
      "\u001b[36meode3rs7bp-algo-1-wkmri |\u001b[0m [2022-01-14 21:04:36 +0000] [34] [INFO] Booting worker with pid: 34\n",
      "\u001b[36meode3rs7bp-algo-1-wkmri |\u001b[0m [2022-01-14 21:04:36 +0000] [35] [INFO] Booting worker with pid: 35\n",
      "\u001b[36meode3rs7bp-algo-1-wkmri |\u001b[0m 2022-01-14 21:04:37,170 INFO - sagemaker-containers - No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36meode3rs7bp-algo-1-wkmri |\u001b[0m /miniconda3/lib/python3.7/site-packages/sklearn/externals/joblib/externals/cloudpickle/cloudpickle.py:47: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n",
      "\u001b[36meode3rs7bp-algo-1-wkmri |\u001b[0m   import imp\n",
      "\u001b[36meode3rs7bp-algo-1-wkmri |\u001b[0m 172.18.0.1 - - [14/Jan/2022:21:04:37 +0000] \"GET /ping HTTP/1.1\" 200 0 \"-\" \"python-urllib3/1.26.7\"\n",
      "\u001b[36meode3rs7bp-algo-1-wkmri |\u001b[0m 172.18.0.1 - - [14/Jan/2022:21:04:37 +0000] \"GET /execution-parameters HTTP/1.1\" 404 232 \"-\" \"python-urllib3/1.26.7\"\n",
      "\u001b[36meode3rs7bp-algo-1-wkmri |\u001b[0m 2022-01-14 21:04:38,279 INFO - sagemaker-containers - No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36meode3rs7bp-algo-1-wkmri |\u001b[0m /miniconda3/lib/python3.7/site-packages/sklearn/externals/joblib/externals/cloudpickle/cloudpickle.py:47: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n",
      "\u001b[36meode3rs7bp-algo-1-wkmri |\u001b[0m   import imp\n",
      "\u001b[36meode3rs7bp-algo-1-wkmri |\u001b[0m 172.18.0.1 - - [14/Jan/2022:21:04:38 +0000] \"POST /invocations HTTP/1.1\" 200 2001189 \"-\" \"python-urllib3/1.26.7\"\n",
      "Gracefully stopping... (press Ctrl+C again to force)\n",
      ".Waiting for transform job: sagemaker-scikit-learn-2022-01-14-21-04-2022-01-14-21-04-31-804\n",
      ".s3://quicksight-sagemaker-demo-accenture/sagemaker/QS-xgboost-churn/transformtrain-train-output/sagemaker-scikit-learn-2022-01-14-21-04-2022-01-14-21-04-31-804\n"
     ]
    }
   ],
   "source": [
    "# Define a SKLearn Transformer from the trained SKLearn Estimator\n",
    "transform_train_output_path = 's3://{}/{}/{}/'.format(bucket, prefix, 'transformtrain-train-output')\n",
    "\n",
    "scikit_learn_inferencee_model = sklearn_preprocessor.create_model(env={'TRANSFORM_MODE': 'feature-transform'})\n",
    "transformer_train = scikit_learn_inferencee_model.transformer(\n",
    "    instance_count=1, \n",
    "    instance_type='local',\n",
    "    assemble_with = 'Line',\n",
    "    output_path = transform_train_output_path,\n",
    "    accept = 'text/csv')\n",
    "\n",
    "\n",
    "# Preprocess training input\n",
    "transformer_train.transform(s3_input_train.config['DataSource']['S3DataSource']['S3Uri'], content_type='text/csv')\n",
    "print('Waiting for transform job: ' + transformer_train.latest_transform_job.job_name)\n",
    "transformer_train.wait()\n",
    "preprocessed_train_path = transformer_train.output_path + transformer_train.latest_transform_job.job_name\n",
    "print(preprocessed_train_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attaching to dl0qqxkizr-algo-1-s7lzw\n",
      "\u001b[36mdl0qqxkizr-algo-1-s7lzw |\u001b[0m Processing /opt/ml/code\n",
      "\u001b[36mdl0qqxkizr-algo-1-s7lzw |\u001b[0m Building wheels for collected packages: preprocessing\n",
      "\u001b[36mdl0qqxkizr-algo-1-s7lzw |\u001b[0m   Building wheel for preprocessing (setup.py) ... \u001b[?25ldone\n",
      "\u001b[36mdl0qqxkizr-algo-1-s7lzw |\u001b[0m \u001b[?25h  Created wheel for preprocessing: filename=preprocessing-1.0.0-py2.py3-none-any.whl size=8211 sha256=8571a944e576f07673a1a2ae18dbbc3bbd391706a09c511e64825c271ec4fc39\n",
      "\u001b[36mdl0qqxkizr-algo-1-s7lzw |\u001b[0m   Stored in directory: /tmp/pip-ephem-wheel-cache-gfawfkck/wheels/3e/0f/51/2f1df833dd0412c1bc2f5ee56baac195b5be563353d111dca6\n",
      "\u001b[36mdl0qqxkizr-algo-1-s7lzw |\u001b[0m Successfully built preprocessing\n",
      "\u001b[36mdl0qqxkizr-algo-1-s7lzw |\u001b[0m Installing collected packages: preprocessing\n",
      "\u001b[36mdl0qqxkizr-algo-1-s7lzw |\u001b[0m Successfully installed preprocessing-1.0.0\n",
      "\u001b[36mdl0qqxkizr-algo-1-s7lzw |\u001b[0m /miniconda3/lib/python3.7/site-packages/sklearn/externals/joblib/externals/cloudpickle/cloudpickle.py:47: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n",
      "\u001b[36mdl0qqxkizr-algo-1-s7lzw |\u001b[0m   import imp\n",
      "\u001b[36mdl0qqxkizr-algo-1-s7lzw |\u001b[0m [2022-01-14 21:04:44 +0000] [35] [INFO] Starting gunicorn 20.1.0\n",
      "\u001b[36mdl0qqxkizr-algo-1-s7lzw |\u001b[0m [2022-01-14 21:04:44 +0000] [35] [INFO] Listening at: unix:/tmp/gunicorn.sock (35)\n",
      "\u001b[36mdl0qqxkizr-algo-1-s7lzw |\u001b[0m [2022-01-14 21:04:44 +0000] [35] [INFO] Using worker: gevent\n",
      "\u001b[36mdl0qqxkizr-algo-1-s7lzw |\u001b[0m [2022-01-14 21:04:44 +0000] [38] [INFO] Booting worker with pid: 38\n",
      "\u001b[36mdl0qqxkizr-algo-1-s7lzw |\u001b[0m [2022-01-14 21:04:44 +0000] [39] [INFO] Booting worker with pid: 39\n",
      "\u001b[36mdl0qqxkizr-algo-1-s7lzw |\u001b[0m 2022-01-14 21:04:45,573 INFO - sagemaker-containers - No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36mdl0qqxkizr-algo-1-s7lzw |\u001b[0m /miniconda3/lib/python3.7/site-packages/sklearn/externals/joblib/externals/cloudpickle/cloudpickle.py:47: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n",
      "\u001b[36mdl0qqxkizr-algo-1-s7lzw |\u001b[0m   import imp\n",
      "\u001b[36mdl0qqxkizr-algo-1-s7lzw |\u001b[0m 172.18.0.1 - - [14/Jan/2022:21:04:46 +0000] \"GET /ping HTTP/1.1\" 200 0 \"-\" \"python-urllib3/1.26.7\"\n",
      "\u001b[36mdl0qqxkizr-algo-1-s7lzw |\u001b[0m 172.18.0.1 - - [14/Jan/2022:21:04:46 +0000] \"GET /execution-parameters HTTP/1.1\" 404 232 \"-\" \"python-urllib3/1.26.7\"\n",
      "\u001b[36mdl0qqxkizr-algo-1-s7lzw |\u001b[0m 2022-01-14 21:04:46,241 INFO - sagemaker-containers - No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36mdl0qqxkizr-algo-1-s7lzw |\u001b[0m /miniconda3/lib/python3.7/site-packages/sklearn/externals/joblib/externals/cloudpickle/cloudpickle.py:47: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n",
      "\u001b[36mdl0qqxkizr-algo-1-s7lzw |\u001b[0m   import imp\n",
      "\u001b[36mdl0qqxkizr-algo-1-s7lzw |\u001b[0m 172.18.0.1 - - [14/Jan/2022:21:04:46 +0000] \"POST /invocations HTTP/1.1\" 200 571727 \"-\" \"python-urllib3/1.26.7\"\n",
      "Gracefully stopping... (press Ctrl+C again to force)\n",
      ".Waiting for transform job: sagemaker-scikit-learn-2022-01-14-21-04-2022-01-14-21-04-40-407\n",
      ".s3://quicksight-sagemaker-demo-accenture/sagemaker/QS-xgboost-churn/transformtrain-validation-output/sagemaker-scikit-learn-2022-01-14-21-04-2022-01-14-21-04-40-407\n"
     ]
    }
   ],
   "source": [
    "# Define a SKLearn Transformer from the trained SKLearn Estimator\n",
    "transform_validation_output_path = 's3://{}/{}/{}/'.format(bucket, prefix, 'transformtrain-validation-output')\n",
    "transformer_validation = scikit_learn_inferencee_model.transformer(\n",
    "    instance_count=1, \n",
    "    instance_type='local',\n",
    "    assemble_with = 'Line',\n",
    "    output_path = transform_validation_output_path,\n",
    "    accept = 'text/csv')\n",
    "# Preprocess validation input\n",
    "transformer_validation.transform(s3_input_validation.config['DataSource']['S3DataSource']['S3Uri'], content_type='text/csv')\n",
    "print('Waiting for transform job: ' + transformer_validation.latest_transform_job.job_name)\n",
    "transformer_validation.wait()\n",
    "preprocessed_validation_path = transformer_validation.output_path+transformer_validation.latest_transform_job.job_name\n",
    "print(preprocessed_validation_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Train\n",
    "\n",
    "Moving onto training, first we'll need to specify the locations of the XGBoost algorithm containers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.amazon.amazon_estimator import get_image_uri\n",
    "container = sagemaker.image_uris.retrieve(\"xgboost\", boto3.Session().region_name, \"1.2-1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, because we're training with the CSV file format, we'll create `s3_input`s that our training function can use as a pointer to the files in S3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'DataSource': {'S3DataSource': {'S3DataType': 'S3Prefix', 'S3Uri': 's3://quicksight-sagemaker-demo-accenture/sagemaker/QS-xgboost-churn/transformtrain-train-output/sagemaker-scikit-learn-2022-01-14-21-04-2022-01-14-21-04-31-804', 'S3DataDistributionType': 'FullyReplicated'}}, 'ContentType': 'text/csv'}\n",
      "{'DataSource': {'S3DataSource': {'S3DataType': 'S3Prefix', 'S3Uri': 's3://quicksight-sagemaker-demo-accenture/sagemaker/QS-xgboost-churn/transformtrain-validation-output/sagemaker-scikit-learn-2022-01-14-21-04-2022-01-14-21-04-40-407', 'S3DataDistributionType': 'FullyReplicated'}}, 'ContentType': 'text/csv'}\n"
     ]
    }
   ],
   "source": [
    "s3_input_train_processed = sagemaker.session.TrainingInput(\n",
    "    preprocessed_train_path, \n",
    "    distribution='FullyReplicated',\n",
    "    content_type='text/csv', \n",
    "    s3_data_type='S3Prefix')\n",
    "print(s3_input_train_processed.config)\n",
    "s3_input_validation_processed = sagemaker.session.TrainingInput(\n",
    "    preprocessed_validation_path, \n",
    "    distribution='FullyReplicated',\n",
    "    content_type='text/csv', \n",
    "    s3_data_type='S3Prefix')\n",
    "print(s3_input_validation_processed.config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can specify a few parameters like what type of training instances we'd like to use and how many, as well as our XGBoost hyperparameters.  A few key hyperparameters are:\n",
    "- `max_depth` controls how deep each tree within the algorithm can be built.  Deeper trees can lead to better fit, but are more computationally expensive and can lead to overfitting.  There is typically some trade-off in model performance that needs to be explored between a large number of shallow trees and a smaller number of deeper trees.\n",
    "- `subsample` controls sampling of the training data.  This technique can help reduce overfitting, but setting it too low can also starve the model of data.\n",
    "- `num_round` controls the number of boosting rounds.  This is essentially the subsequent models that are trained using the residuals of previous iterations.  Again, more rounds should produce a better fit on the training data, but can be computationally expensive or lead to overfitting.\n",
    "- `eta` controls how aggressive each round of boosting is.  Larger values lead to more conservative boosting.\n",
    "- `gamma` controls how aggressively trees are grown.  Larger values lead to more conservative models.\n",
    "\n",
    "More detail on XGBoost's hyperparmeters can be found on their GitHub [page](https://github.com/dmlc/xgboost/blob/master/doc/parameter.md)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-01-14 21:04:48 Starting - Starting the training job...\n",
      "2022-01-14 21:05:12 Starting - Launching requested ML instancesProfilerReport-1642194287: InProgress\n",
      "......\n",
      "2022-01-14 21:06:12 Starting - Preparing the instances for training............\n",
      "2022-01-14 21:08:13 Downloading - Downloading input data\n",
      "2022-01-14 21:08:13 Training - Downloading the training image......\n",
      "2022-01-14 21:09:15 Uploading - Uploading generated training model.\u001b[34m[2022-01-14 21:09:11.584 ip-10-2-97-59.ec2.internal:1 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\u001b[0m\n",
      "\u001b[34mINFO:sagemaker-containers:Imported framework sagemaker_xgboost_container.training\u001b[0m\n",
      "\u001b[34mINFO:sagemaker-containers:Failed to parse hyperparameter objective value binary:logistic to Json.\u001b[0m\n",
      "\u001b[34mReturning the value itself\u001b[0m\n",
      "\u001b[34mINFO:sagemaker-containers:No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34mINFO:sagemaker_xgboost_container.training:Running XGBoost Sagemaker in algorithm mode\u001b[0m\n",
      "\u001b[34mINFO:root:Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34mINFO:root:Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34mINFO:root:Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34mINFO:root:Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34mINFO:root:Single node training.\u001b[0m\n",
      "\u001b[34mINFO:root:Train matrix has 3500 rows and 99 columns\u001b[0m\n",
      "\u001b[34mINFO:root:Validation matrix has 1000 rows\u001b[0m\n",
      "\u001b[34m[0]#011train-error:0.11743#011validation-error:0.12700\u001b[0m\n",
      "\u001b[34m[1]#011train-error:0.10429#011validation-error:0.10800\u001b[0m\n",
      "\u001b[34m[2]#011train-error:0.09714#011validation-error:0.10700\u001b[0m\n",
      "\u001b[34m[3]#011train-error:0.08600#011validation-error:0.10300\u001b[0m\n",
      "\u001b[34m[4]#011train-error:0.08457#011validation-error:0.09700\u001b[0m\n",
      "\u001b[34m[5]#011train-error:0.08143#011validation-error:0.09200\u001b[0m\n",
      "\u001b[34m[6]#011train-error:0.07714#011validation-error:0.08700\u001b[0m\n",
      "\u001b[34m[7]#011train-error:0.07343#011validation-error:0.08300\u001b[0m\n",
      "\u001b[34m[8]#011train-error:0.07029#011validation-error:0.07700\u001b[0m\n",
      "\u001b[34m[9]#011train-error:0.06914#011validation-error:0.07800\u001b[0m\n",
      "\u001b[34m[10]#011train-error:0.06657#011validation-error:0.07900\u001b[0m\n",
      "\u001b[34m[11]#011train-error:0.06543#011validation-error:0.07300\u001b[0m\n",
      "\u001b[34m[12]#011train-error:0.06343#011validation-error:0.07500\u001b[0m\n",
      "\u001b[34m[13]#011train-error:0.06286#011validation-error:0.07000\u001b[0m\n",
      "\u001b[34m[14]#011train-error:0.06286#011validation-error:0.07200\u001b[0m\n",
      "\u001b[34m[15]#011train-error:0.06400#011validation-error:0.07100\u001b[0m\n",
      "\u001b[34m[16]#011train-error:0.06286#011validation-error:0.07200\u001b[0m\n",
      "\u001b[34m[17]#011train-error:0.06200#011validation-error:0.06900\u001b[0m\n",
      "\u001b[34m[18]#011train-error:0.06000#011validation-error:0.06900\u001b[0m\n",
      "\u001b[34m[19]#011train-error:0.06000#011validation-error:0.06700\u001b[0m\n",
      "\u001b[34m[20]#011train-error:0.05971#011validation-error:0.06300\u001b[0m\n",
      "\u001b[34m[21]#011train-error:0.05914#011validation-error:0.06600\u001b[0m\n",
      "\u001b[34m[22]#011train-error:0.05914#011validation-error:0.06700\u001b[0m\n",
      "\u001b[34m[23]#011train-error:0.05800#011validation-error:0.06600\u001b[0m\n",
      "\u001b[34m[24]#011train-error:0.05800#011validation-error:0.07000\u001b[0m\n",
      "\u001b[34m[25]#011train-error:0.05800#011validation-error:0.06800\u001b[0m\n",
      "\u001b[34m[26]#011train-error:0.05600#011validation-error:0.06600\u001b[0m\n",
      "\u001b[34m[27]#011train-error:0.05600#011validation-error:0.06600\u001b[0m\n",
      "\u001b[34m[28]#011train-error:0.05514#011validation-error:0.06800\u001b[0m\n",
      "\u001b[34m[29]#011train-error:0.05514#011validation-error:0.06300\u001b[0m\n",
      "\u001b[34m[30]#011train-error:0.05343#011validation-error:0.06500\u001b[0m\n",
      "\u001b[34m[31]#011train-error:0.05229#011validation-error:0.06600\u001b[0m\n",
      "\u001b[34m[32]#011train-error:0.05171#011validation-error:0.06800\u001b[0m\n",
      "\u001b[34m[33]#011train-error:0.05171#011validation-error:0.06800\u001b[0m\n",
      "\u001b[34m[34]#011train-error:0.05086#011validation-error:0.06500\u001b[0m\n",
      "\u001b[34m[35]#011train-error:0.05057#011validation-error:0.06600\u001b[0m\n",
      "\u001b[34m[36]#011train-error:0.05029#011validation-error:0.06500\u001b[0m\n",
      "\u001b[34m[37]#011train-error:0.05057#011validation-error:0.06500\u001b[0m\n",
      "\u001b[34m[38]#011train-error:0.05057#011validation-error:0.06400\u001b[0m\n",
      "\u001b[34m[39]#011train-error:0.05000#011validation-error:0.06400\u001b[0m\n",
      "\u001b[34m[40]#011train-error:0.04857#011validation-error:0.06300\u001b[0m\n",
      "\u001b[34m[41]#011train-error:0.04771#011validation-error:0.06400\u001b[0m\n",
      "\u001b[34m[42]#011train-error:0.04771#011validation-error:0.06500\u001b[0m\n",
      "\u001b[34m[43]#011train-error:0.04771#011validation-error:0.06600\u001b[0m\n",
      "\u001b[34m[44]#011train-error:0.04629#011validation-error:0.06400\u001b[0m\n",
      "\u001b[34m[45]#011train-error:0.04543#011validation-error:0.06400\u001b[0m\n",
      "\u001b[34m[46]#011train-error:0.04514#011validation-error:0.06400\u001b[0m\n",
      "\u001b[34m[47]#011train-error:0.04343#011validation-error:0.06300\u001b[0m\n",
      "\u001b[34m[48]#011train-error:0.04343#011validation-error:0.06300\u001b[0m\n",
      "\u001b[34m[49]#011train-error:0.04343#011validation-error:0.06300\u001b[0m\n",
      "\u001b[34m[50]#011train-error:0.04343#011validation-error:0.06400\u001b[0m\n",
      "\u001b[34m[51]#011train-error:0.04314#011validation-error:0.06400\u001b[0m\n",
      "\u001b[34m[52]#011train-error:0.04257#011validation-error:0.06500\u001b[0m\n",
      "\u001b[34m[53]#011train-error:0.04229#011validation-error:0.06400\u001b[0m\n",
      "\u001b[34m[54]#011train-error:0.04229#011validation-error:0.06400\u001b[0m\n",
      "\u001b[34m[55]#011train-error:0.04314#011validation-error:0.06500\u001b[0m\n",
      "\u001b[34m[56]#011train-error:0.04200#011validation-error:0.06300\u001b[0m\n",
      "\u001b[34m[57]#011train-error:0.04086#011validation-error:0.06200\u001b[0m\n",
      "\u001b[34m[58]#011train-error:0.04057#011validation-error:0.06200\u001b[0m\n",
      "\u001b[34m[59]#011train-error:0.04000#011validation-error:0.06100\u001b[0m\n",
      "\u001b[34m[60]#011train-error:0.04143#011validation-error:0.06300\u001b[0m\n",
      "\u001b[34m[61]#011train-error:0.04143#011validation-error:0.06300\u001b[0m\n",
      "\u001b[34m[62]#011train-error:0.04114#011validation-error:0.05900\u001b[0m\n",
      "\u001b[34m[63]#011train-error:0.04114#011validation-error:0.06100\u001b[0m\n",
      "\u001b[34m[64]#011train-error:0.04000#011validation-error:0.06100\u001b[0m\n",
      "\u001b[34m[65]#011train-error:0.04029#011validation-error:0.06100\u001b[0m\n",
      "\u001b[34m[66]#011train-error:0.04029#011validation-error:0.06100\u001b[0m\n",
      "\u001b[34m[67]#011train-error:0.04000#011validation-error:0.06000\u001b[0m\n",
      "\u001b[34m[68]#011train-error:0.03971#011validation-error:0.06000\u001b[0m\n",
      "\u001b[34m[69]#011train-error:0.03886#011validation-error:0.06100\u001b[0m\n",
      "\u001b[34m[70]#011train-error:0.03857#011validation-error:0.06000\u001b[0m\n",
      "\u001b[34m[71]#011train-error:0.03857#011validation-error:0.06000\u001b[0m\n",
      "\u001b[34m[72]#011train-error:0.03800#011validation-error:0.06000\u001b[0m\n",
      "\u001b[34m[73]#011train-error:0.03829#011validation-error:0.06000\u001b[0m\n",
      "\u001b[34m[74]#011train-error:0.03800#011validation-error:0.06000\u001b[0m\n",
      "\u001b[34m[75]#011train-error:0.03743#011validation-error:0.06000\u001b[0m\n",
      "\u001b[34m[76]#011train-error:0.03743#011validation-error:0.06100\u001b[0m\n",
      "\u001b[34m[77]#011train-error:0.03829#011validation-error:0.06100\u001b[0m\n",
      "\u001b[34m[78]#011train-error:0.03857#011validation-error:0.06100\u001b[0m\n",
      "\u001b[34m[79]#011train-error:0.03800#011validation-error:0.05900\u001b[0m\n",
      "\u001b[34m[80]#011train-error:0.03857#011validation-error:0.06000\u001b[0m\n",
      "\u001b[34m[81]#011train-error:0.03829#011validation-error:0.06000\u001b[0m\n",
      "\u001b[34m[82]#011train-error:0.03829#011validation-error:0.06000\u001b[0m\n",
      "\u001b[34m[83]#011train-error:0.03829#011validation-error:0.06000\u001b[0m\n",
      "\u001b[34m[84]#011train-error:0.03800#011validation-error:0.05900\u001b[0m\n",
      "\u001b[34m[85]#011train-error:0.03771#011validation-error:0.06100\u001b[0m\n",
      "\u001b[34m[86]#011train-error:0.03800#011validation-error:0.06100\u001b[0m\n",
      "\u001b[34m[87]#011train-error:0.03771#011validation-error:0.06100\u001b[0m\n",
      "\u001b[34m[88]#011train-error:0.03771#011validation-error:0.06100\u001b[0m\n",
      "\u001b[34m[89]#011train-error:0.03714#011validation-error:0.06000\u001b[0m\n",
      "\u001b[34m[90]#011train-error:0.03686#011validation-error:0.05800\u001b[0m\n",
      "\u001b[34m[91]#011train-error:0.03600#011validation-error:0.06000\u001b[0m\n",
      "\u001b[34m[92]#011train-error:0.03600#011validation-error:0.06000\u001b[0m\n",
      "\u001b[34m[93]#011train-error:0.03657#011validation-error:0.06000\u001b[0m\n",
      "\u001b[34m[94]#011train-error:0.03629#011validation-error:0.05900\u001b[0m\n",
      "\u001b[34m[95]#011train-error:0.03543#011validation-error:0.05800\u001b[0m\n",
      "\u001b[34m[96]#011train-error:0.03543#011validation-error:0.05800\u001b[0m\n",
      "\u001b[34m[97]#011train-error:0.03543#011validation-error:0.05800\u001b[0m\n",
      "\u001b[34m[98]#011train-error:0.03571#011validation-error:0.05800\u001b[0m\n",
      "\u001b[34m[99]#011train-error:0.03371#011validation-error:0.05700\u001b[0m\n",
      "\n",
      "2022-01-14 21:09:33 Completed - Training job completed\n",
      "ProfilerReport-1642194287: NoIssuesFound\n",
      "Training seconds: 84\n",
      "Billable seconds: 84\n"
     ]
    }
   ],
   "source": [
    "sess = sagemaker.Session()\n",
    "\n",
    "xgb = sagemaker.estimator.Estimator(container,\n",
    "                                    role, \n",
    "                                    instance_count=1, \n",
    "                                    instance_type='ml.m4.xlarge',\n",
    "                                    output_path='s3://{}/{}/output'.format(bucket, prefix),\n",
    "                                    sagemaker_session=sess)\n",
    "xgb.set_hyperparameters(max_depth=5,\n",
    "                        eta=0.2,\n",
    "                        gamma=4,\n",
    "                        min_child_weight=6,\n",
    "                        subsample=0.8,\n",
    "                        objective='binary:logistic',\n",
    "                        num_round=100)\n",
    "\n",
    "xgb.fit({'train': s3_input_train_processed, 'validation': s3_input_validation_processed}) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Post-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a SKLearn Transformer from the trained SKLearn Estimator\n",
    "transform_postprocessor_path = 's3://{}/{}/{}/'.format(bucket, prefix, 'transformtrain-postprocessing-output')\n",
    "scikit_learn_post_process_model = sklearn_preprocessor.create_model(env={'TRANSFORM_MODE': 'inverse-label-transform'})\n",
    "transformer_post_processing = scikit_learn_post_process_model.transformer(\n",
    "    instance_count=1, \n",
    "    instance_type='local',\n",
    "    assemble_with = 'Line',\n",
    "    output_path = transform_postprocessor_path,\n",
    "    accept = 'text/csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference Pipeline <a class=\"anchor\" id=\"pipeline_setup\"></a>\n",
    "Setting up a Machine Learning pipeline can be done with the create_model(). In this example, we configure our pipeline model with the fitted Scikit-learn inference model, the fitted Xgboost model and the psotprocessing model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'QS-inference-pipeline-2022-01-14-21-10-01'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timestamp_prefix = strftime(\"%Y-%m-%d-%H-%M-%S\", gmtime())\n",
    "model_name = 'QS-inference-pipeline-' + timestamp_prefix\n",
    "client = boto3.client('sagemaker')\n",
    "response = client.create_model(\n",
    "    ModelName=model_name,\n",
    "    Containers=[\n",
    "        {\n",
    "            'Image': sklearn_preprocessor.image_uri,\n",
    "            'ModelDataUrl': sklearn_preprocessor.model_data,\n",
    "            'Environment': {\n",
    "                    \"SAGEMAKER_SUBMIT_DIRECTORY\": sklearn_preprocessor.uploaded_code.s3_prefix,\n",
    "                    \"TRANSFORM_MODE\": \"feature-transform\",\n",
    "                    \"SAGEMAKER_CONTAINER_LOG_LEVEL\": str(sklearn_preprocessor.container_log_level),\n",
    "                    \"SAGEMAKER_REGION\": sklearn_preprocessor.sagemaker_session.boto_region_name,\n",
    "                    \"SAGEMAKER_PROGRAM\": sklearn_preprocessor.uploaded_code.script_name\n",
    "                }\n",
    "        },\n",
    "        {\n",
    "            'Image': xgb.image_uri,\n",
    "            'ModelDataUrl': xgb.model_data,\n",
    "            \"Environment\": {}\n",
    "        },\n",
    "        {\n",
    "            'Image': scikit_learn_post_process_model.image_uri,\n",
    "            'ModelDataUrl': scikit_learn_post_process_model.model_data,\n",
    "            'Environment': {\n",
    "                    \"SAGEMAKER_SUBMIT_DIRECTORY\": sklearn_preprocessor.uploaded_code.s3_prefix,\n",
    "                    \"TRANSFORM_MODE\": \"inverse-label-transform\",\n",
    "                    \"SAGEMAKER_CONTAINER_LOG_LEVEL\": str(sklearn_preprocessor.container_log_level),\n",
    "                    \"SAGEMAKER_REGION\": sklearn_preprocessor.sagemaker_session.boto_region_name,\n",
    "                    \"SAGEMAKER_PROGRAM\": sklearn_preprocessor.uploaded_code.script_name\n",
    "                }\n",
    "        },\n",
    "    ],\n",
    "    ExecutionRoleArn = role,\n",
    ")\n",
    "model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "notice": "Copyright 2017 Amazon.com, Inc. or its affiliates. All Rights Reserved.  Licensed under the Apache License, Version 2.0 (the \"License\"). You may not use this file except in compliance with the License. A copy of the License is located at http://aws.amazon.com/apache2.0/ or in the \"license\" file accompanying this file. This file is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License."
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
